Okay, here is a summary of the key prompt types discussed in the sources, organised into a Markdown table as you requested.

Please note that the marketing-specific examples provided are adaptations of the general examples found in the sources and are not directly from the source material.

| Prompt Name                  | General Example                                                                                                                                                                                                                                                                                          | When to Use It                                                                                                                                                                                                                                                                                                                         | Marketing-Specific Example                                                                                                                                                                                                                                                                                                                         |
| :--------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **General Prompting / Zero Shot** | `Classify movie reviews as POSITIVE, NEUTRAL or NEGATIVE. Review: "Her" is a disturbing study revealing the direction humanity is headed if AI is allowed to keep evolving, unchecked. I wish there were more movies like this masterpiece. Sentiment:`                                              | This is the simplest type of prompt, used when you only provide a task description and starting text. It is a good starting point but may fail for more complex tasks or when a specific output structure is needed.                                                                                                        | `Classify customer feedback as POSITIVE, NEUTRAL, or NEGATIVE. Feedback: "The new product update is terrible, it broke everything! I can't even log in anymore, but the old version was great." Sentiment:` (Adaptation of)                                                                                                   |
| **One-shot**                 | `Parse a customer's pizza order into valid JSON: EXAMPLE: I want a small pizza with cheese, tomato sauce, and pepperoni. JSON Response: `̀ ` { "size": "small", "type": "normal", "ingredients": [["cheese", "tomato sauce", "peperoni"]] } `̀ `` (Adaptation of with one example)             | Use when zero-shot fails. Providing a single example helps the model understand and imitate the desired output structure or pattern. Useful for steering the model towards a specific format.                                                                                                                   | `Parse a customer query into JSON: EXAMPLE: I need help resetting my password. JSON Response: `̀ ` { "intent": "password reset", "details": "need help resetting" } `̀ `` (Adaptation of with one example)                                                                                                                      |
| **Few-shot**                 | `Parse a customer's pizza order into valid JSON: EXAMPLE: I want a small pizza with cheese, tomato sauce, and pepperoni. JSON Response: `̀ ` { "size": "small", "type": "normal", "ingredients": [["cheese", "tomato sauce", "peperoni"]] } `̀ ` EXAMPLE: Can I get a large pizza with tomato sauce, basil and mozzarella { "size": "large", "type": "normal", "ingredients": [["tomato sauce", "bazel", "mozzarella"]] } Now, I would like a large pizza, with the first half cheese and mozzarella. And the other tomato sauce, ham and pineapple. JSON Response:` | Use when zero-shot fails. Provides multiple examples to show the model a pattern. Increases the chance the model follows the desired structure or pattern compared to one-shot. Especially useful for classification tasks by mixing classes in examples. Needs 3-5+ examples typically.                 | `Parse product reviews into JSON summaries: EXAMPLE: Review: "Great headphones, long battery life and comfortable!" JSON: { "product": "headphones", "summary": "long battery, comfortable", "sentiment": "positive" } EXAMPLE: Review: "Website is slow and confusing to navigate." JSON: { "product": "website", "summary": "slow, confusing navigation", "sentiment": "negative" } Review: "App crashes frequently on Android." JSON:` (Adaptation of for reviews) |
| **System Prompting**         | `Classify movie reviews as positive, neutral or negative. Return valid JSON:` followed by the schema and review text. (See for full example including schema)                                                                                                                     | Defines the model's fundamental capabilities and overarching purpose. Sets the overall context and specifies how to return output. Useful for meeting specific requirements like language compatibility, structure (e.g., JSON), or controlling safety/toxicity.                                          | `You are a marketing copy generator. Generate product descriptions for an e-commerce website. Always return output in valid JSON format with keys "product_name", "short_description", and "key_features" as a list of strings.` (Adaptation of)                                                                 |
| **Role Prompting**           | `I want you to act as a travel guide. I will write to you about my location and you will suggest 3 places to visit near me. In some cases, I will also give you the type of places I will visit. My suggestion: "I am in Amsterdam and I want to visit only museums." Travel Suggestions:` | Frames the model's output style and voice by assigning a specific character or identity. Helps the model generate responses consistent with the assigned role's knowledge and behavior. Useful for tailoring tone and style.                                                              | `Act as a cheerful and energetic social media manager for a fitness brand. Write a short post promoting our new workout plan. Post:` (Adaptation of)                                                                                                                                                                   |
| **Contextual Prompting**     | `Context: You are writing for a blog about retro 80's arcade video games. Suggest 3 topics to write an article about with a few lines of description of what this article should contain.`                                                                                                  | Provides immediate, task-specific information to guide the response. Helps the model understand nuances and tailor its output; highly specific and dynamic. Useful for providing background information relevant to the current conversation or task.                                                | `Context: The target audience is small business owners looking for digital marketing tips. Suggest 3 topics for a blog post about SEO with a few lines of description for each.` (Adaptation of)                                                                                                                       |
| **Step-back Prompting**      | `Context: 5 engaging themes for a first person shooter video game: [List of themes from step-back prompt] Take one of the themes and write a one paragraph storyline for a new level of a first-person shooter video game that is challenging and engaging.` (The first prompt was the "step back" question: `Based on popular first-person shooter action games, what are 5 fictional key settings...`) | Improves performance by prompting the LLM to first consider a general question, then using that answer in the specific task prompt. Activates relevant background knowledge/reasoning, encourages critical thinking, mitigates bias, and increases accuracy. Useful for complex or challenging tasks. | *(This technique involves a two-step process. First prompt, the "step back"):* `Based on successful digital marketing campaigns, what are 3 key psychological triggers that compel customers to buy?` *(Second prompt, using the step-back answer as context):* `Context: Key psychological triggers in marketing include [List triggers from step-back answer]. Write a 3-sentence product description for a new coffee machine using one of these triggers.` (Adaptation of) |
| **Chain of Thought (CoT)**   | `When I was 3 years old, my partner was 3 times my age. Now, I am 20 years old. How old is my partner? Let's think step by step.` (See for the detailed output steps)                                                                                                                | Improves reasoning by generating intermediate steps. Leads to more accurate answers, interpretability, and robustness. Particularly useful for tasks where LLMs struggle with direct answers, like math problems. Any task that can be solved by breaking it down into steps.                   | `Outline a content marketing strategy for a new local bakery. Let's think step by step.` (Adaptation of for a planning task)                                                                                                                                                                             |
| **Self-consistency**         | `EMAIL: [Email text from source] Classify the above email as IMPORTANT or NOT IMPORTANT. Let's think step by step and explain why.` (Note: This prompt structure is similar to zero-shot CoT. The technique involves running this prompt multiple times with higher temperature and taking the majority answer). | Improves Chain of Thought reasoning by combining sampling (high temperature) and majority voting across diverse reasoning paths. Useful for improving accuracy and coherence, especially when a single CoT run might be inconsistent. Comes with higher computational costs.           | `CUSTOMER FEEDBACK: [Feedback text about a marketing email campaign] Classify the above feedback as POSITIVE or NEGATIVE impact on campaign goals. Let's think step by step and explain why.` (Adaptation of for marketing feedback classification)                                                   |
| **Tree of Thoughts (ToT)**   | *No specific prompt example provided in the source.*                                                                                                                                                                                                                         | Generalizes Chain of Thought to explore multiple reasoning paths simultaneously, rather than just a single linear chain. Suitable for complex tasks that require exploration and maintaining a tree of possible "thoughts" or intermediate steps.                                                    | *No specific prompt example provided in the source to adapt for marketing.*                                                                                                                                                                                                                         |
| **ReAct (reason & act)**     | `How many kids do the band members of Metallica have?` (Note: This simple query triggers a more complex thought-action loop that requires external tools and code implementation).                                                                                     | A paradigm that combines natural language reasoning with external tools (like search or code interpreters). Allows the LLM to interact with external APIs to retrieve information or perform actions. Useful for tasks requiring up-to-date information or interaction with external systems.           | `Find the average social media engagement rate for the top 5 fashion brands in the UK in the last month.` (Adaptation of for a marketing task requiring external search via code implementation)                                                                                                      |

This table summarises the primary prompt types and related techniques presented in the sources, along with their use cases and illustrative examples.
